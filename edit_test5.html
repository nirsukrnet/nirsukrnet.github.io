<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Audio Segment Tester (Refactored)</title>
    <style>
        body { font-family: sans-serif; padding: 20px; max-width: 800px; margin: 0 auto; }
        .control-group2 { margin-bottom: 15px; padding: 15px; background: #f5f5f5; border-radius: 8px; }

        label { display: inline-block; width: 100px; font-weight: bold; }
        input[type="number"] { padding: 5px; width: 100px; }
        button { padding: 8px 16px; cursor: pointer; font-size: 16px; margin-right: 10px; }
        #status2 { margin-bottom: 10px; font-style: italic; color: #666; }
        .control-group-btns2 { margin-bottom: 15px; }
        #log { margin-top: 20px; background: #eee; padding: 10px; height: 200px; overflow-y: auto; font-family: monospace; font-size: 12px; border: 1px solid #ccc; }
        audio { width: 100%; margin-top: 10px; }

        /* Timeline Visualization */
        .marker { position: absolute; height: 100%; top: 0; }

        /* Visualization Container */
        .vis-container2 { border: 2px solid #ccc; border-radius: 6px; padding: 10px; margin-top: 15px; background: #fff; position: relative; height: 120px; overflow: hidden; }

        /* Spectrum Canvas */
        #spectrum2 { width: 100%; height: 100%; background: #000; margin-top: 0; border: 1px solid #333; display: block; }
        
        /* Adjust timeline margin inside container */
        #timeline2 { position: absolute; top: 10px; left: 10px; right: 10px; bottom: 10px; border: none; pointer-events: none; }
        
        /* Markers */
        .marker { position: absolute; height: 100%; top: 0; width: 2px; background-color: rgba(255, 255, 255, 0.8); pointer-events: none; }
        
        .marker-handle {
            width: 16px;
            height: 16px;
            background-color: #fff;
            border: 2px solid #333;
            border-radius: 50%;
            position: absolute;
            top: -8px; /* Center vertically on top edge or just above */
            left: -8px; /* Center horizontally */
            cursor: pointer;
            pointer-events: auto;
            z-index: 10;
        }

        #segmentHighlight {
            position: absolute;
            top: 0;
            height: 100%;
            background-color: rgba(0, 255, 0, 0.2); /* Green highlight for segment */
            border: 1px solid rgba(0, 255, 0, 0.6);
            pointer-events: auto;
            cursor: grab;
            z-index: 5;
        }

        #segmentHighlight:active {
            cursor: grabbing;
        }

        #segmentHighlight .highlight-handle {
            background-color: rgba(0, 255, 0, 0.8);
        }

        /* Global Timeline (Rule 1) */
        #FirstFrameWithBorder { border: 2px solid #333; border-radius: 8px; padding: 10px; margin-top: 20px; background: #f9f9f9; }
        .vis-container1 { position: relative; height: 60px; border: 1px solid #ccc; background: #000; }
        #spectrum1 { width: 100%; height: 100%; display: block; }
        #viewWindowHighlight {
            position: absolute;
            top: 0;
            height: 100%;
            background-color: rgba(255, 255, 0, 0.3); /* Yellow highlight */
            border: 1px solid rgba(255, 255, 0, 0.8);
            pointer-events: auto; /* Enable pointer events for dragging */
            cursor: grab;
        }
        
        #viewWindowHighlight:active {
            cursor: grabbing;
        }

        .highlight-handle {
            position: absolute;
            top: 0;
            bottom: 0;
            width: 10px;
            cursor: ew-resize;
            background-color: rgba(255, 255, 0, 0.5);
            z-index: 10;
        }

        .handle-start { left: -5px; }
        .handle-end { right: -5px; }

        #SecondFrameWithBorder { border: 2px solid #333; border-radius: 8px; padding: 20px; margin-top: 20px; }
    </style>
</head>
<body>
    <h1>Audio Segment Tester (Refactored)</h1>    

    <!-- Rule 1: Global Timeline -->
    <div id="FirstFrameWithBorder">
        <div style="font-weight: bold; margin-bottom: 5px;">Global Timeline (Entire File)</div>
        <div class="vis-container1">
            <canvas id="spectrum1"></canvas>
            <div id="viewWindowHighlight">
                <div class="highlight-handle handle-start"></div>
                <div class="highlight-handle handle-end"></div>
            </div>
        </div>
        <div id="status1" style="font-size: 12px; color: #666; margin-top: 5px;">Loading...</div>
    </div>

    <!-- Rule 2: Segment Timeline -->
    <div id="SecondFrameWithBorder">
    <div id="status2">Editing</div>

    <div class="control-group2">
        <div>
            <label for="startTime2">Start Time:</label>
            <input type="number" id="startTime2" value="20.00" step="0.01"> sec
        </div>
        <div style="margin-top: 10px;">
            <label for="endTime2">End Time:</label>
            <input type="number" id="endTime2" value="25.00" step="0.01"> sec
        </div>
    </div>

    <div class="control-group-btns2">
        <button id="btnPlay2">Play Segment</button>
        <button id="btnStop2">Stop</button>
    </div>

    <audio id="audioPlayer2" controls style="display: none;"></audio>

    <div class="vis-container2">
        <canvas id="spectrum2"></canvas>
        <div id="timeline2">
            <div id="segmentHighlight">
                <div class="highlight-handle handle-start"></div>
                <div class="highlight-handle handle-end"></div>
            </div>
            <div id="markerCurrent2" class="marker" title="Current Position"></div>
        </div>
    </div>
    </div>


    <h3>Debug Log</h3>
    <div id="log"></div>

    <script>
        // ==========================================
        // LIBRARY CODE (Reusable Functions)
        // ==========================================

        /**
         * 1. Visualization
         * 1.1) Renders the waveform, time ruler, and playhead cursor onto the provided canvas.
         */
        function drawWaveform(canvas, audioBuffer, start, end, currentTime) {
            if (!audioBuffer) return canvas;
            
            const canvasCtx = canvas.getContext('2d');

            if (isNaN(start) || isNaN(end) || start >= end) return canvas;

            // Get logical size (CSS pixels)
            const width = canvas.width / (window.devicePixelRatio || 1);
            const height = canvas.height / (window.devicePixelRatio || 1);

            // Clear canvas
            canvasCtx.clearRect(0, 0, width, height);
            canvasCtx.fillStyle = '#1a1a1a'; // Darker background
            canvasCtx.fillRect(0, 0, width, height);

            // Get data
            const rawData = audioBuffer.getChannelData(0); // Use channel 0
            const sampleRate = audioBuffer.sampleRate;
            
            const startSample = Math.floor(start * sampleRate);
            const endSample = Math.floor(end * sampleRate);
            const totalSamples = endSample - startSample;
            
            // Draw Waveform
            canvasCtx.lineWidth = 1;
            canvasCtx.fillStyle = '#ff5252'; // Filled shape color
            canvasCtx.beginPath();

            const step = Math.ceil(totalSamples / width);
            const amp = height / 2;

            // Draw top half
            canvasCtx.moveTo(0, amp);
            for (let i = 0; i < width; i++) {
                let min = 1.0;
                let max = -1.0;
                
                for (let j = 0; j < step; j++) {
                    const datum = rawData[startSample + (i * step) + j];
                    if (datum < min) min = datum;
                    if (datum > max) max = datum;
                }
                
                // Draw to the max point
                canvasCtx.lineTo(i, (1 - max) * amp);
            }

            // Draw bottom half (mirror)
            for (let i = width - 1; i >= 0; i--) {
                let min = 1.0;
                let max = -1.0;
                
                for (let j = 0; j < step; j++) {
                    const datum = rawData[startSample + (i * step) + j];
                    if (datum < min) min = datum;
                    if (datum > max) max = datum;
                }
                
                // Draw to the min point
                canvasCtx.lineTo(i, (1 - min) * amp);
            }
            
            canvasCtx.closePath();
            canvasCtx.fill();

            // Draw Ruler Scale
            const duration = end - start;
            canvasCtx.fillStyle = 'rgba(255, 255, 255, 0.9)';
            canvasCtx.strokeStyle = 'rgba(255, 255, 255, 0.2)';
            canvasCtx.font = '11px sans-serif';
            canvasCtx.textAlign = 'center';
            canvasCtx.lineWidth = 1;

            // Determine step size based on duration
            let tickStep = 1;
            if (duration <= 1) tickStep = 0.1;
            else if (duration <= 5) tickStep = 0.5;
            else if (duration <= 10) tickStep = 1;
            else tickStep = 5;

            // Find first tick
            const firstTick = Math.ceil(start / tickStep) * tickStep;
            
            for (let t = firstTick; t < end; t += tickStep) {
                const x = (t - start) / duration * width;
                
                // Draw tick mark
                canvasCtx.beginPath();
                canvasCtx.moveTo(x, 0);
                canvasCtx.lineTo(x, 15);
                canvasCtx.stroke();

                // Draw grid line (faint)
                canvasCtx.beginPath();
                canvasCtx.moveTo(x, 15);
                canvasCtx.lineTo(x, height);
                canvasCtx.stroke();

                // Draw label
                canvasCtx.fillText(t.toFixed(1), x, 28);
            }

            // Draw Playhead Cursor
            if (currentTime >= start && currentTime <= end) {
                const progress = (currentTime - start) / (end - start);
                const x = progress * width;
                
                canvasCtx.strokeStyle = '#ffffff';
                canvasCtx.lineWidth = 2;
                canvasCtx.beginPath();
                canvasCtx.moveTo(x, 0);
                canvasCtx.lineTo(x, height);
                canvasCtx.stroke();
            }
            return canvas;
        }

        /**
         * 1. Visualization
         * 1.1) Adjusts the canvas width/height attributes to match display size and pixel density.
         */
        function resizeCanvas(canvas) {
            const dpr = window.devicePixelRatio || 1;
            const rect = canvas.getBoundingClientRect();
            const canvasCtx = canvas.getContext('2d');
            
            // Set actual size in memory (scaled to account for extra pixel density)
            canvas.width = rect.width * dpr;
            canvas.height = rect.height * dpr;
            
            // Normalize coordinate system to use css pixels
            canvasCtx.scale(dpr, dpr);
            
            return canvas;
        }

        /**
         * 2. Audio Processing
         * 1.1) Decodes a Blob or ArrayBuffer into an AudioBuffer for visualization.
         */
        async function decodeAudioData(audioCtx, blob) {
            const arrayBuffer = await blob.arrayBuffer();
            return await audioCtx.decodeAudioData(arrayBuffer);
        }

        /**
         * 3. Playback Control
         * 1.1) Plays audio from a start time and stops automatically at an end time. Returns the interval ID for cancellation.
         */
        function playSegment(audioElement, start, end) {
            if (isNaN(start) || isNaN(end) || start >= end) {
                console.log("Invalid start/end times.");
                return null;
            }

            // Set time
            audioElement.currentTime = start;

            // Polling loop to wait for seek to complete
            const intervalId = setInterval(() => {
                // Check if currentTime is close enough to target start time
                if (audioElement.currentTime >= start - 0.1) {
                    clearInterval(intervalId);
                    
                    audioElement.play().then(() => {
                        // Set up stop listener
                        const timeUpdateHandler = () => {
                            if (audioElement.currentTime >= end) {
                                audioElement.pause();
                                audioElement.removeEventListener('timeupdate', timeUpdateHandler);
                            }
                        };
                        audioElement.addEventListener('timeupdate', timeUpdateHandler);
                    }).catch(e => console.log(`Play failed: ${e.message}`));
                }
            }, 50);

            return intervalId;
        }

        /**
         * 3. Playback Control
         * 1.1) Stops audio playback and clears any active segment monitoring intervals.
         */
        function stopPlayback(audioElement, intervalId) {
            audioElement.pause();
            if (intervalId) {
                clearInterval(intervalId);
            }
            return audioElement;
        }

        /**
         * 4. UI Updates
         * 1.1) Updates the visual position of the current playback marker based on time.
         */
        function updateProgressMarker(markerElement, current, start, duration) {
             // Calculate percentage relative to the segment
             let percentage = (current - start) / duration * 100;
            
             // Clamp visual marker to 0-100% to avoid it flying off if audio plays slightly outside
             percentage = Math.max(0, Math.min(100, percentage));
 
             markerElement.style.left = percentage + '%';
             return markerElement;
        }

        /**
         * 4. UI Updates
         * 1.1) Sets the positions of start and end markers (typically 0% and 100% for zoomed view).
         */
        function updateRangeMarkers(startMarker, endMarker) {
            startMarker.style.left = '0%';
            endMarker.style.left = '100%';
            return { startMarker, endMarker };
        }


        // ==========================================
        // IMPLEMENTATION CODE (Specific to this page)
        // ==========================================

        const logEl = document.getElementById('log');

        function log(msg) {
            const time = new Date().toISOString().split('T')[1].slice(0, -1);
            logEl.innerHTML += `[${time}] ${msg}<br>`;
            logEl.scrollTop = logEl.scrollHeight;
            console.log(msg);
        }

        // 1. Define Context Objects
        const context1 = {
            id: 1,
            // Global timeline doesn't need playback controls for now, just visualization
            statusEl: document.getElementById('status1'),
            canvas: document.getElementById('spectrum1'),
            highlight: document.getElementById('viewWindowHighlight'),
            handleStart: document.querySelector('#viewWindowHighlight .handle-start'),
            handleEnd: document.querySelector('#viewWindowHighlight .handle-end'),
            isWaveformReady: false,
            audioBuffer: null,
            audioCtx: null,
            dragState: {
                isDragging: false,
                target: null, // 'start', 'end', or 'body'
                startX: 0,
                initialStart: 0,
                initialEnd: 0
            }
        };

        const context2 = {
            id: 2,
            audio: document.getElementById('audioPlayer2'),
            statusEl: document.getElementById('status2'),
            btnPlay: document.getElementById('btnPlay2'),
            btnStop: document.getElementById('btnStop2'),
            inputStart: document.getElementById('startTime2'),
            inputEnd: document.getElementById('endTime2'),
            canvas: document.getElementById('spectrum2'),
            segmentHighlight: document.getElementById('segmentHighlight'),
            handleStart: document.querySelector('#segmentHighlight .handle-start'),
            handleEnd: document.querySelector('#segmentHighlight .handle-end'),
            markerCurrent: document.getElementById('markerCurrent2'),
            timeline: document.getElementById('timeline2'),
            checkSeekInterval: null,
            isWaveformReady: false,
            audioBuffer: null,
            audioCtx: null,
            // View Window for Context 2
            viewStart: 0,
            viewEnd: 0,
            dragState: {
                isDragging: false,
                target: null,
                startX: 0,
                initialStart: 0,
                initialEnd: 0
            }
        };

        const contexts = [context1, context2];

        // 2. Refactor Functions to Accept Context

        function updateGlobalHighlight(ctxGlobal, ctxSegment) {
            if (!ctxGlobal.highlight || !ctxSegment.audioBuffer) return;
            
            const totalDuration = ctxSegment.audioBuffer.duration;
            if (totalDuration <= 0) return;

            // Use View Window (viewStart/viewEnd) to show the visible range
            const start = ctxSegment.viewStart;
            const end = ctxSegment.viewEnd;

            const startPct = (start / totalDuration) * 100;
            const endPct = (end / totalDuration) * 100;
            const widthPct = endPct - startPct;

            ctxGlobal.highlight.style.left = startPct + '%';
            ctxGlobal.highlight.style.width = widthPct + '%';
        }

        function setupGlobalDragInteraction(ctxGlobal, ctxSegment) {
            const overlay = ctxGlobal.highlight;
            const handleStart = ctxGlobal.handleStart;
            const handleEnd = ctxGlobal.handleEnd;

            const onMouseDown = (e, target) => {
                e.stopPropagation(); // Prevent bubbling
                ctxGlobal.dragState.isDragging = true;
                ctxGlobal.dragState.target = target;
                ctxGlobal.dragState.startX = e.clientX;
                // Store initial View Window state
                ctxGlobal.dragState.initialStart = ctxSegment.viewStart;
                ctxGlobal.dragState.initialEnd = ctxSegment.viewEnd;
                
                window.addEventListener('mousemove', handleGlobalDrag);
                window.addEventListener('mouseup', stopGlobalDrag);
            };

            // Bind events
            overlay.addEventListener('mousedown', (e) => onMouseDown(e, 'body'));
            handleStart.addEventListener('mousedown', (e) => onMouseDown(e, 'start'));
            handleEnd.addEventListener('mousedown', (e) => onMouseDown(e, 'end'));

            function handleGlobalDrag(e) {
                if (!ctxGlobal.dragState.isDragging) return;
                
                const rect = ctxGlobal.canvas.getBoundingClientRect();
                const totalDuration = ctxGlobal.audioBuffer.duration;
                
                const deltaPx = e.clientX - ctxGlobal.dragState.startX;
                const deltaSeconds = (deltaPx / rect.width) * totalDuration;
                
                let newStart = ctxGlobal.dragState.initialStart;
                let newEnd = ctxGlobal.dragState.initialEnd;

                if (ctxGlobal.dragState.target === 'body') {
                    newStart += deltaSeconds;
                    newEnd += deltaSeconds;
                } else if (ctxGlobal.dragState.target === 'start') {
                    newStart += deltaSeconds;
                } else if (ctxGlobal.dragState.target === 'end') {
                    newEnd += deltaSeconds;
                }
                
                // Constraints
                if (ctxGlobal.dragState.target === 'body') {
                    // Clamp to bounds while maintaining duration
                    if (newStart < 0) {
                        const duration = newEnd - newStart;
                        newStart = 0;
                        newEnd = duration;
                    }
                    if (newEnd > totalDuration) {
                        const duration = newEnd - newStart;
                        newEnd = totalDuration;
                        newStart = totalDuration - duration;
                    }
                } else {
                    // Clamp individual markers
                    newStart = Math.max(0, Math.min(newStart, totalDuration));
                    newEnd = Math.max(0, Math.min(newEnd, totalDuration));
                    
                    // Prevent crossover
                    if (newStart > newEnd) {
                        if (ctxGlobal.dragState.target === 'start') newStart = newEnd - 0.1;
                        if (ctxGlobal.dragState.target === 'end') newEnd = newStart + 0.1;
                    }
                }
                
                // Update View Window ONLY
                ctxSegment.viewStart = newStart;
                ctxSegment.viewEnd = newEnd;
                
                // Trigger updates
                // handleUpdateMarkers(ctxSegment); // Disabled to prevent touching segment highlight during global drag
                updateGlobalHighlight(ctxGlobal, ctxSegment); // Update Global Highlight
            }
            
            function stopGlobalDrag() {
                ctxGlobal.dragState.isDragging = false;
                window.removeEventListener('mousemove', handleGlobalDrag);
                window.removeEventListener('mouseup', stopGlobalDrag);
                
                handleUpdateMarkers(ctxSegment); // Sync Frame 2 UI after drag completes
                
                const start = ctxSegment.viewStart.toFixed(2);
                const end = ctxSegment.viewEnd.toFixed(2);
                log(`[Frame 1] Action: ${ctxGlobal.dragState.target}. New View Window: ${start}s - ${end}s`);
            }
        }

        function handleUpdateMarkers(ctx) {
            if (ctx.id === 2 && ctx.segmentHighlight) {
                // Context 2: Position relative to View Window
                const start = parseFloat(ctx.inputStart.value);
                const end = parseFloat(ctx.inputEnd.value);
                const duration = ctx.viewEnd - ctx.viewStart;
                
                if (duration > 0) {
                    const rawStartPct = ((start - ctx.viewStart) / duration) * 100;
                    const rawEndPct = ((end - ctx.viewStart) / duration) * 100;
                    
                    // Visual Clamp to ensure the box stays within the container visually
                    // This handles cases where the segment is partially or fully out of view
                    const visStartPct = Math.max(0, Math.min(100, rawStartPct));
                    const visEndPct = Math.max(0, Math.min(100, rawEndPct));
                    const visWidthPct = visEndPct - visStartPct;
                    
                    ctx.segmentHighlight.style.left = visStartPct + '%';
                    ctx.segmentHighlight.style.width = visWidthPct + '%';
                    
                    // Hide if fully out of view to prevent artifacts
                    ctx.segmentHighlight.style.display = visWidthPct > 0 ? 'block' : 'none';
                }
                
                // Sync Global Highlight whenever markers update
                updateGlobalHighlight(context1, context2);
            } else if (ctx.markerStart && ctx.markerEnd) {
                // Context 1: Fixed 0-100% (if it had markers)
                updateRangeMarkers(ctx.markerStart, ctx.markerEnd);
            }
        }

        function handleUpdateCurrentMarker(ctx) {
            if (!ctx.markerCurrent) return;

            const start = parseFloat(ctx.inputStart.value);
            const end = parseFloat(ctx.inputEnd.value);
            const current = ctx.audio.currentTime;
            
            if (ctx.id === 2) {
                 const duration = ctx.viewEnd - ctx.viewStart;
                 if (duration > 0) {
                     const pct = ((current - ctx.viewStart) / duration) * 100;
                     ctx.markerCurrent.style.left = Math.max(0, Math.min(100, pct)) + '%';
                 }
            } else {
                const duration = end - start;
                updateProgressMarker(ctx.markerCurrent, current, start, duration);
            }
        }

        function handleResizeCanvas(ctx) {
            if (ctx.canvas) {
                resizeCanvas(ctx.canvas);
            }
        }

        function handleStopPlayback(ctx) {
            stopPlayback(ctx.audio, ctx.checkSeekInterval);
            ctx.checkSeekInterval = null;
            log(`[Frame ${ctx.id}] Playback stopped.`);
        }

        function handlePlaySegment(ctx) {
            const start = parseFloat(ctx.inputStart.value);
            const end = parseFloat(ctx.inputEnd.value);

            log(`[Frame ${ctx.id}] Requesting playback: ${start}s -> ${end}s`);
            
            handleStopPlayback(ctx);

            ctx.checkSeekInterval = playSegment(ctx.audio, start, end);
            
            if (ctx.checkSeekInterval) {
                 log(`[Frame ${ctx.id}] Seek initiated...`);
            }
        }

        // Animation Loop (Handles all contexts)
        function animate() {
            contexts.forEach(ctx => {
                if (ctx.isWaveformReady && ctx.audioBuffer && ctx.canvas) {
                    let start, end;
                    
                    if (ctx.id === 1) {
                        // Global View: Entire File
                        start = 0;
                        end = ctx.audioBuffer.duration;
                    } else if (ctx.id === 2) {
                        // Draw View Window
                        start = ctx.viewStart;
                        end = ctx.viewEnd;
                    } else {
                        // Draw Segment
                        start = parseFloat(ctx.inputStart.value);
                        end = parseFloat(ctx.inputEnd.value);
                    }
                    
                    // For Context 1, we don't have a player attached usually, or we can use context2's player time
                    // For now, let's just pass 0 or context2's time if we want to see playhead globally
                    const current = (ctx.id === 1 && context2.audio) ? context2.audio.currentTime : (ctx.audio ? ctx.audio.currentTime : 0);
                    
                    drawWaveform(ctx.canvas, ctx.audioBuffer, start, end, current);
                }
            });
            requestAnimationFrame(animate);
        }

        // Drag Logic for Context 2
        function initDragHandlers(ctx) {
            if (ctx.id !== 2) return;

            const timeline = ctx.timeline;
            const overlay = ctx.segmentHighlight;
            const handleStart = ctx.handleStart;
            const handleEnd = ctx.handleEnd;

            const onMouseDown = (e, target) => {
                e.stopPropagation();
                ctx.dragState.isDragging = true;
                ctx.dragState.target = target;
                ctx.dragState.startX = e.clientX;
                ctx.dragState.initialStart = parseFloat(ctx.inputStart.value);
                ctx.dragState.initialEnd = parseFloat(ctx.inputEnd.value);
                
                window.addEventListener('mousemove', handleDrag);
                window.addEventListener('mouseup', stopDrag);
            };

            overlay.addEventListener('mousedown', (e) => onMouseDown(e, 'body'));
            handleStart.addEventListener('mousedown', (e) => onMouseDown(e, 'start'));
            handleEnd.addEventListener('mousedown', (e) => onMouseDown(e, 'end'));

            function handleDrag(e) {
                if (!ctx.dragState.isDragging) return;

                const rect = timeline.getBoundingClientRect();
                const deltaPixels = e.clientX - ctx.dragState.startX;
                const viewDuration = ctx.viewEnd - ctx.viewStart;
                const deltaSeconds = (deltaPixels / rect.width) * viewDuration;
                
                let newStart = ctx.dragState.initialStart;
                let newEnd = ctx.dragState.initialEnd;
                
                if (ctx.dragState.target === 'body') {
                    newStart += deltaSeconds;
                    newEnd += deltaSeconds;
                } else if (ctx.dragState.target === 'start') {
                    newStart += deltaSeconds;
                } else if (ctx.dragState.target === 'end') {
                    newEnd += deltaSeconds;
                }

                // Constraints
                const currentStart = parseFloat(ctx.inputStart.value);
                const currentEnd = parseFloat(ctx.inputEnd.value);
                
                // Boundary Constraints (Recalculation)
                if (ctx.dragState.target === 'body') {
                    // Calculate duration from the proposed new values to ensure consistency
                    const duration = newEnd - newStart;
                    
                    // Clamp Start
                    if (newStart < ctx.viewStart) {
                        // log(`[Debug] Clamping Start: ${newStart} -> ${ctx.viewStart}`);
                        newStart = ctx.viewStart;
                        newEnd = newStart + duration;
                    }
                    
                    // Clamp End
                    if (newEnd > ctx.viewEnd) {
                        // log(`[Debug] Clamping End: ${newEnd} -> ${ctx.viewEnd}`);
                        newEnd = ctx.viewEnd;
                        newStart = newEnd - duration;
                    }
                    
                    // Double-check Start (in case duration > viewWidth)
                    if (newStart < ctx.viewStart) {
                        newStart = ctx.viewStart;
                    }
                } else {
                    // Clamp individual markers
                    if (ctx.dragState.target === 'start') {
                        newStart = Math.min(newStart, currentEnd - 0.1);
                        newStart = Math.max(newStart, ctx.viewStart);
                    } else {
                        newEnd = Math.max(newEnd, currentStart + 0.1);
                        newEnd = Math.min(newEnd, ctx.viewEnd);
                    }
                }
                
                ctx.inputStart.value = newStart.toFixed(2);
                ctx.inputEnd.value = newEnd.toFixed(2);
                
                handleUpdateMarkers(ctx);
            }

            function stopDrag() {
                if (ctx.dragState.isDragging) {
                    ctx.dragState.isDragging = false;
                    window.removeEventListener('mousemove', handleDrag);
                    window.removeEventListener('mouseup', stopDrag);
                    log(`[Frame ${ctx.id}] Drag complete. New range: ${ctx.inputStart.value} - ${ctx.inputEnd.value}`);
                }
            }
        }

        // Initialization
        async function loadSharedAudio(url) {
            try {
                // 1. Fetch and Decode Once
                log(`[System] Fetching ${url}...`);
                const response = await fetch(url);
                if (!response.ok) throw new Error(`HTTP error! status: ${response.status}`);
                
                const blob = await response.blob();
                log(`[System] Blob loaded. Size: ${(blob.size / 1024 / 1024).toFixed(2)} MB`);
                
                log(`[System] Decoding audio data...`);
                const audioCtx = new (window.AudioContext || window.webkitAudioContext)();
                const arrayBuffer = await blob.arrayBuffer();
                const audioBuffer = await audioCtx.decodeAudioData(arrayBuffer);
                log(`[System] Audio decoded. Duration: ${audioBuffer.duration.toFixed(2)}s`);

                // 2. Initialize Context 1 (Global)
                context1.audioCtx = audioCtx;
                context1.audioBuffer = audioBuffer;
                context1.isWaveformReady = true;
                context1.statusEl.textContent = "Ready";

                // 3. Initialize Context 2 (Segment Editor)
                context2.audioCtx = audioCtx;
                context2.audioBuffer = audioBuffer;
                context2.isWaveformReady = true;
                
                // Setup Audio Element for Playback (Context 2 only)
                const blobUrl = URL.createObjectURL(blob);
                context2.audio.src = blobUrl;
                context2.statusEl.textContent = "Ready";

                // Setup View Window for Context 2
                const segmentStart = parseFloat(context2.inputStart.value);
                const segmentEnd = parseFloat(context2.inputEnd.value);
                const duration = audioBuffer.duration;
                
                const windowSize = 60; // 60 seconds window
                const center = (segmentStart + segmentEnd) / 2;
                
                context2.viewStart = Math.max(0, center - windowSize / 2);
                context2.viewEnd = Math.min(duration, center + windowSize / 2);
                
                log(`[Frame 2] View Window set: ${context2.viewStart.toFixed(2)}s - ${context2.viewEnd.toFixed(2)}s`);
                
                initDragHandlers(context2);
                
                // Setup Global Drag Interaction
                setupGlobalDragInteraction(context1, context2);
                
                // Sync Global Highlight
                updateGlobalHighlight(context1, context2);
                log(`[Frame 1] Global Highlight initialized.`);

                // 4. Initial Draw
                handleResizeCanvas(context1);
                handleResizeCanvas(context2);
                handleUpdateMarkers(context2);

            } catch (e) {
                log(`[Error] ${e.message}`);
                if (context1.statusEl) context1.statusEl.textContent = "Error";
                if (context2.statusEl) context2.statusEl.textContent = "Error";
            }
        }

        // 3. Bind Event Listeners
        contexts.forEach(ctx => {
            if (ctx.btnPlay) ctx.btnPlay.addEventListener('click', () => handlePlaySegment(ctx));
            if (ctx.btnStop) ctx.btnStop.addEventListener('click', () => handleStopPlayback(ctx));
            
            if (ctx.inputStart) ctx.inputStart.addEventListener('input', () => handleUpdateMarkers(ctx));
            if (ctx.inputEnd) ctx.inputEnd.addEventListener('input', () => handleUpdateMarkers(ctx));
            
            if (ctx.audio) {
                ctx.audio.addEventListener('loadedmetadata', () => handleUpdateMarkers(ctx));
                ctx.audio.addEventListener('timeupdate', () => handleUpdateCurrentMarker(ctx));
            }
        });

        window.addEventListener('resize', () => {
            contexts.forEach(ctx => handleResizeCanvas(ctx));
        });

        // Start Animation Loop
        animate();

        // Start
        loadSharedAudio('phrase_audio/SW_Learn_Day_1-5.mp3');
    </script>
</body>
</html>